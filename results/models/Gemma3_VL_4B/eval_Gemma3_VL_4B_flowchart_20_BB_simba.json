{"question_id": "20240603102225671652", "prompt": "How many types of symbols are there in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "5", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "How many oval symbols are there in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "2", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "How many rectangular symbols are there in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "5", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What is the color of the diamond symbol?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Lightyellow", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What is the color of the parallelogram symbol?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Lightgreen", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What does the arrow symbol represent in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Transition", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What does the diamond symbol represent in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Decision", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What does the rectangle symbol represent in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Process", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What does the oval symbol represent in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Start/End", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
{"question_id": "20240603102225671652", "prompt": "What does the parallelogram symbol represent in the flowchart?", "text": "Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 572.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.83 GiB is allocated by PyTorch, and 3.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Input/Output", "type": "flowchart", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "flowchart"}}
