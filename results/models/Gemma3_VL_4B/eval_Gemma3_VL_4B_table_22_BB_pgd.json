{"question_id": "20240202141559370876", "prompt": "How many columns are there in the table?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "2", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the title of the table?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Monthly E-commerce sales in dollars for the year 2021", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What are the names of the columns?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Month, E-commerce sales (dollars)", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the value of the cell in the first row and the first column?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "2021/01", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the column name of the cell with the value 95000?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "E-commerce sales (dollars)", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the largest value in the table?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "165000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the smallest value in the table?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "75000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the second largest value in the table?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "145000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the value of the cell in the third row and second column?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "95000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the value of the cell in the last row and first column?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "2021/12", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the column name of the cell with the value 2021/07?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Month", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the difference between the highest and lowest E-commerce sales?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "90000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the sum of the E-commerce sales from January to December?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "1275000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the average E-commerce sales per month?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "106250", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the median value of E-commerce sales?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "102500", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What's the ratio of the highest sales to the lowest sales?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "2.2", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the difference between the E-commerce sales in January and December?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "90000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the sum of the E-commerce sales in the first half of the year?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "555000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What is the sum of the E-commerce sales in the second half of the year?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "720000", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What's the caption of this chart?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "Monthly E-commerce sales in dollars for the year 2021", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202141559370876", "prompt": "What's the summary of this chart?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "The data shows the monthly E-commerce sales in dollars for the year 2021. It depicts a general growth trend in sales, starting from 75,000 dollars in January and peaking at 165,000 dollars in December. This indicates a successful year for the E-commerce business with an increase in sales throughout the year.", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
{"question_id": "20240202222616910185", "prompt": "How many columns are there in the table?", "text": "Error: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 566.81 MiB is free. Including non-PyTorch memory, this process has 6.98 GiB memory in use. 6.84 GiB allowed; Of the allocated memory 6.72 GiB is allocated by PyTorch, and 118.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)", "truth": "2", "type": "table", "answer_id": "", "markers": [], "model_id": "Gemma3_VL_4B", "metadata": {"adversarial": true, "task": "table"}}
